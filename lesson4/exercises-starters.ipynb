{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "This is the notebook containing the exercises for Feature Store, Model Monitor, and Clarify. Tested for these exercises was performed using __2 vCPU + 4 GiB notebook instance with Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized) kernel__.\n",
    "\n",
    "## Staging\n",
    "\n",
    "We'll begin by initializing some variables. These are often assumed to be present in code samples you'll find in the AWS documenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Store\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature store is a special database to give ML systems a consistent data flow across training and inference workloads. It can ingest data in batches (for training) as well as serve input features to models with very low latency for real-time prediction.\n",
    "\n",
    "For this exercise we'll work with a wine quality dataset: https://archive.ics.uci.edu/ml/datasets/wine+quality/\n",
    "\n",
    "```P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we leave the column names as-is, Feature Store won't be able to handle the `/` in `od280/od315_of_diluted_wines` (`/` is a delimiter Feature Store uses to manage how features are organized.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our data, we can create a feature group. Remember to attach event time and ID columns - Feature Store needs them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureDefinition(feature_name='alcohol', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='malic_acid', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='alcalinity_of_ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='magnesium', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='total_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='flavanoids', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='nonflavanoid_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='proanthocyanins', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='color_intensity', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='hue', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='od280_od315_of_diluted_wines', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='proline', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='EventTime', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='id', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a feature group\n",
    "df[\"EventTime\"] = time.time()\n",
    "df[\"id\"] = range(len(df))\n",
    "\n",
    "# TODO: Create feature group\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "feature_group = FeatureGroup(name='boston-features', sagemaker_session=session)\n",
    "\n",
    "# TODO: Load Feature definitions\n",
    "feature_group.load_feature_definitions(data_frame=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature group is not created until we call the `create` method, let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:086566025687:feature-group/boston-features',\n",
       " 'ResponseMetadata': {'RequestId': 'dcb0f1f6-4b4d-4138-b5c9-260d1a8e421e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'dcb0f1f6-4b4d-4138-b5c9-260d1a8e421e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '92',\n",
       "   'date': 'Wed, 25 May 2022 12:50:27 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "feature_group.create(\n",
    "    s3_uri='s3://sagemaker-studio-upalsdlzrg/lesson-4/features',\n",
    "    record_identifier_name='id', # Name of the column that needs to be unique for all records\n",
    "    event_time_feature_name='EventTime', # Name of the column for the event time\n",
    "    role_arn=role,\n",
    "    enable_online_store=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, ingest some data into your feature group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IngestionManagerPandas(feature_group_name='boston-features', sagemaker_session=<sagemaker.session.Session object at 0x7fbbf2350fd0>, data_frame=     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280_od315_of_diluted_wines  proline     EventTime   id  \n",
       "0                            3.92   1065.0  1.653483e+09    0  \n",
       "1                            3.40   1050.0  1.653483e+09    1  \n",
       "2                            3.17   1185.0  1.653483e+09    2  \n",
       "3                            3.45   1480.0  1.653483e+09    3  \n",
       "4                            2.93    735.0  1.653483e+09    4  \n",
       "..                            ...      ...           ...  ...  \n",
       "173                          1.74    740.0  1.653483e+09  173  \n",
       "174                          1.56    750.0  1.653483e+09  174  \n",
       "175                          1.56    835.0  1.653483e+09  175  \n",
       "176                          1.62    840.0  1.653483e+09  176  \n",
       "177                          1.60    560.0  1.653483e+09  177  \n",
       "\n",
       "[178 rows x 15 columns], max_workers=1, _futures={<Future at 0x7fbbf1512400 state=finished returned NoneType>: (0, 178)})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.ingest(data_frame=df, max_workers=3, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You've demonstrated your understanding of creating feature groups and ingesting data into them using Feature Store. Next up we'll cover Model Monitor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we'll create a monitoring schedule for a deployed model. We're going to provide code to help you deploy a model and get started, so that you can focus on Model Monitor for this exercise. __Remember to clean up your model before you end a work session__. We'll provide some code at the end to help you clean up your model. We'll begin by reloading our data from the previous exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = data['target']\n",
    "df.set_index(df.pop('TARGET'), inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = int(len(df)/2)\n",
    "train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-31 08:08:22 Starting - Starting the training job...\n",
      "2022-05-31 08:08:48 Starting - Preparing the instances for trainingProfilerReport-1653984501: InProgress\n",
      "............\n",
      "2022-05-31 08:10:40 Downloading - Downloading input data...\n",
      "2022-05-31 08:11:20 Training - Downloading the training image......\n",
      "2022-05-31 08:12:20 Uploading - Uploading generated training model\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2022-05-31:08:12:13:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2022-05-31:08:12:13:INFO] File size need to be processed in the node: 0.01mb. Available memory size in the node: 8496.18mb\u001b[0m\n",
      "\u001b[34m[2022-05-31:08:12:13:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:12:13] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[08:12:13] 89x13 matrix with 1157 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2022-05-31:08:12:13:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:12:13] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[08:12:13] 89x13 matrix with 1157 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[08:12:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.9357#011validation-rmse:0.53422\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.759657#011validation-rmse:0.685354\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.616137#011validation-rmse:0.821641\u001b[0m\n",
      "\u001b[34m[08:12:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[08:12:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[08:12:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[08:12:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[08:12:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[08:12:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.501087#011validation-rmse:0.858446\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.430041#011validation-rmse:0.925116\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.377443#011validation-rmse:0.979923\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.337549#011validation-rmse:1.0265\u001b[0m\n",
      "\u001b[34m[08:12:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[08:12:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.309158#011validation-rmse:1.06425\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.287472#011validation-rmse:1.09787\u001b[0m\n",
      "\u001b[34m[08:12:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.273879#011validation-rmse:1.12296\u001b[0m\n",
      "\u001b[34m[08:12:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.264732#011validation-rmse:1.1432\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.9357#011validation-rmse:0.53422\u001b[0m\n",
      "\n",
      "2022-05-31 08:12:40 Completed - Training job completed\n",
      "Training seconds: 118\n",
      "Billable seconds: 118\n"
     ]
    }
   ],
   "source": [
    "algo_image = sagemaker.image_uris.retrieve(\"xgboost\", region, version='latest')\n",
    "s3_output_location = f\"s3://{bucket}/models/wine_model\"\n",
    "\n",
    "model=sagemaker.estimator.Estimator(\n",
    "    image_uri=algo_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    volume_size=5,\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")\n",
    "\n",
    "model.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)\n",
    "\n",
    "\n",
    "model.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your training job has finished, you can perform the first task in this exercise: creating a data capture config. Configure your model to sample `34%` of inferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "capture_uri = f\"s3://{bucket}/models_outputs/wine_model\"\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=capture_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We'll use your config to deploy a model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You should see an indicator like this when the deployment finishes:\n",
    "\n",
    "```\n",
    "-----------------!\n",
    "```\n",
    "We can test your deployment like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6030303239822388,0.6030303239822388,0.6030303239822388,0.6030303239822388,0.6030303239822388'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "inputs = test.copy()\n",
    "# Drop the target variable\n",
    "inputs = inputs.drop(columns=inputs.columns[0])\n",
    "x_pred = xgb_predictor.predict(inputs.sample(5).values).decode('utf-8')\n",
    "x_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All systems go! To finish up the exercise, we're going to provide you with a DefaultModelMonitor and a suggested baseline. Combine the `xgb_predictor` and the provided `my_monitor` to configure the monitoring schedule for _hourly_ monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrainingInput' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6741fdaa058b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m my_monitor.suggest_baseline(\n\u001b[1;32m      2\u001b[0m     \u001b[0mbaseline_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms3_input_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdataset_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetFormat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b[0m in \u001b[0;36msuggest_baseline\u001b[0;34m(self, baseline_dataset, dataset_format, record_preprocessor_script, post_analytics_processor_script, output_s3_uri, wait, logs, job_name)\u001b[0m\n\u001b[1;32m   1414\u001b[0m                 )\n\u001b[1;32m   1415\u001b[0m             ),\n\u001b[0;32m-> 1416\u001b[0;31m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_BASELINE_DATASET_INPUT_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1417\u001b[0m         )\n\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/model_monitor/model_monitoring.py\u001b[0m in \u001b[0;36m_upload_and_convert_to_processing_input\u001b[0;34m(self, source, destination, name)\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m         \u001b[0mparse_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparse_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"s3\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/urllib/parse.py\u001b[0m in \u001b[0;36murlparse\u001b[0;34m(url, scheme, allow_fragments)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0mNote\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mbreak\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcomponents\u001b[0m \u001b[0mup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmaller\u001b[0m \u001b[0mbits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\n\u001b[0;32m--> 367\u001b[0;31m     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_coerce_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_coerce_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m     \u001b[0msplitresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fragments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/urllib/parse.py\u001b[0m in \u001b[0;36m_coerce_args\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_noop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decode_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_encode_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m# Result objects are more helpful than simple tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/urllib/parse.py\u001b[0m in \u001b[0;36m_decode_args\u001b[0;34m(args, encoding, errors)\u001b[0m\n\u001b[1;32m    105\u001b[0m def _decode_args(args, encoding=_implicit_encoding,\n\u001b[1;32m    106\u001b[0m                        errors=_implicit_errors):\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_coerce_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/urllib/parse.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    105\u001b[0m def _decode_args(args, encoding=_implicit_encoding,\n\u001b[1;32m    106\u001b[0m                        errors=_implicit_errors):\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_coerce_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TrainingInput' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "my_monitor.suggest_baseline(\n",
    "    baseline_dataset=f's3://{bucket}/data/train.csv',\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, provide the monitoring schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "my_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name='wine-model-monitoring',\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    statistics=my_monitor.baseline_statistics(),\n",
    "    constraints=my_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You can check that your schedule was created by selecting the `SageMaker components and registries` tab on the far left.\n",
    "\n",
    "In this exercise you configured Model Monitor to watch a simple model. Next, we'll monitor the same deployment for explainability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. If you aren't going to follow up with the Clarify exercise within a few hours, use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()CronExpressionGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarify\n",
    "\n",
    "For the last exercise we'll deploy an explainability monitor using Clarify. We're going to use the model that you deployed in the last exercise, but if you cleaned up your deployments from the previous exercise, that's ok! You can rerun the deployment from the previous exercise up to the point where we deployed our model. It'll look like this:\n",
    "\n",
    "```python\n",
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")\n",
    "```\n",
    "\n",
    "Once your model is deployed, you can come back here. _REMINDER_: you need to clean up your deployment, don't leave it running overnight. We'll provide some code at the end to delete your deployment.\n",
    "\n",
    "## Prep\n",
    "\n",
    "We'll begin by reloading our data from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = data['target']\n",
    "df.set_index(df.pop('TARGET'), inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = int(len(df)/2)\n",
    "train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our data is staged and our model is deployed - let's monitor it for explainability. We need to define three config objects, the `SHAPConfig`, the `ModelConfig`, and the `ExplainabilityAnalysisConfig`. Below, we provide the `SHAPConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=[train.mean().astype(int).to_list()[1:]],\n",
    "    num_samples=int(train.size),\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, fill in the blanks to define the `ModelConfig` and `ExplainabilityAnalysisConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=xgb_predictor.endpoint_name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    content_type=\"text/csv\",\n",
    "    accept_type=\"text/csv\")\n",
    "\n",
    "analysis_config = sagemaker.model_monitor.ExplainabilityAnalysisConfig(\n",
    "        explainability_config=shap_config,\n",
    "        model_config=model_config,\n",
    "        headers=train.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we apply our config, we need to create the monitor object. This is what we'll apply all our config to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor = sagemaker.model_monitor.ModelExplainabilityMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything's ready! Below, create a monitoring schedule using the configs we created. Set the schedule to run _daily_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "explainability_uri = f'{capture_uri}/explainability'\n",
    "model_explainability_monitor.create_monitoring_schedule(\n",
    "    output_s3_uri=explainability_uri,\n",
    "    analysis_config=analysis_config,\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    schedule_cron_expression=CronExpressionGenerator.daily(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way to go! You can check that your schedule was created by selecting the `SageMaker components and registries` tab on the far left.\n",
    "\n",
    "In this exercise you deployed a monitor for explainability to your SageMaker endpoint. This is the last exercise - you'll apply these learnings again in your Project at the end of the course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. Use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: monitoring-schedule-2022-05-31-09-09-59-162\n",
      "\n",
      "Deleting Monitoring Schedule with name: wine-model-monitoring\n"
     ]
    }
   ],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
